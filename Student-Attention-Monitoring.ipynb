{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25847 sha256=2f65d825533d8e249ca2062b796945da080712932bf9b539e28029324b48c753\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\85\\cf\\3a\\e265e975a1e7c7e54eb3692d6aa4e2e7d6a3945d29da46f2d7\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gTTs\n",
      "  Downloading gTTS-2.3.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: requests~=2.28.0 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from gTTs) (2.28.1)\n",
      "Requirement already satisfied: six~=1.16.0 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from gTTs) (1.16.0)\n",
      "Requirement already satisfied: click~=8.1.3 in c:\\users\\asus\\.conda\\envs\\aireadiness\\lib\\site-packages (from gTTs) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from click~=8.1.3->gTTs) (0.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from requests~=2.28.0->gTTs) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from requests~=2.28.0->gTTs) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from requests~=2.28.0->gTTs) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from requests~=2.28.0->gTTs) (2.1.1)\n",
      "Installing collected packages: gTTs\n",
      "Successfully installed gTTs-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gTTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py): started\n",
      "  Building wheel for playsound (setup.py): finished with status 'done'\n",
      "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7020 sha256=c716952201af84c72e0807a8568b671226fdb1bf7933fe2178d8c70ad568b73b\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\90\\89\\ed\\2d643f4226fc8c7c9156fc28abd8051e2d2c0de37ae51ac45c\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "from imutils import face_utils\n",
    "from threading import Thread\n",
    "from gtts import gTTS\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/images\\\\1_joey-friends.jpg', 'data/images\\\\forw1.jpg', 'data/images\\\\joye.jpg', 'data/images\\\\left01.jpg', 'data/images\\\\left02.jpg', 'data/images\\\\left03.jpg', 'data/images\\\\left04.jpg', 'data/images\\\\left05.jpg', 'data/images\\\\left06.jpg', 'data/images\\\\left07.jpg', 'data/images\\\\left08.jpg', 'data/images\\\\left09.jpg', 'data/images\\\\left11.jpg', 'data/images\\\\left12.jpg', 'data/images\\\\left13.jpg', 'data/images\\\\left14.jpg', 'data/images\\\\left15.jpg', 'data/images\\\\right1.jpg']\n",
      "[[841.03841995   0.         299.82147851]\n",
      " [  0.         795.35092229 311.11137452]\n",
      " [  0.           0.           1.        ]]\n",
      "[[-0.74385783  1.22763835 -0.06298022  0.02514577 -4.96593631]]\n",
      "[[532.31551799   0.         339.8746808 ]\n",
      " [  0.         533.20299198 229.95766405]\n",
      " [  0.           0.           1.        ]]\n",
      "[[-2.74923328e-01 -1.16425935e-01  1.97353060e-03 -2.80934499e-04\n",
      "   6.99029347e-01]]\n",
      "[[534.66009875   0.         338.04563279]\n",
      " [  0.         535.23103875 233.17885002]\n",
      " [  0.           0.           1.        ]]\n",
      "[[-0.29859772  0.15622958  0.00161868 -0.00059438 -0.04155775]]\n",
      "[[532.84697556   0.         338.36938031]\n",
      " [  0.         532.96420007 232.3225661 ]\n",
      " [  0.           0.           1.        ]]\n",
      "[[-0.29156285  0.10805925  0.00205759 -0.00092031  0.08343395]]\n",
      "[[534.34144579   0.         339.15527836]\n",
      " [  0.         534.68425882 233.84359493]\n",
      " [  0.           0.           1.        ]]\n",
      "[[-2.88320983e-01  5.41079685e-02  1.73501622e-03 -2.61333895e-04\n",
      "   2.04110465e-01]]\n",
      "[[534.23975673   0.         339.48785767]\n",
      " [  0.         534.48885733 233.1201801 ]\n",
      " [  0.           0.           1.        ]]\n",
      "[[-0.29800288  0.16066574  0.00158846 -0.00033622 -0.06800946]]\n",
      "[[534.09050351   0.         339.75719693]\n",
      " [  0.         534.3178381  233.13618843]\n",
      " [  0.           0.           1.        ]]\n",
      "[[-3.03020486e-01  1.76149345e-01  1.51645329e-03 -4.80550013e-05\n",
      "  -8.53855132e-02]]\n",
      "[[534.17982188   0.         341.22392645]\n",
      " [  0.         534.42712122 233.96164532]\n",
      " [  0.           0.           1.        ]]\n",
      "[[-3.05041222e-01  1.88567156e-01  1.55700506e-03  5.80965865e-05\n",
      "  -1.13923108e-01]]\n",
      "[[534.21305012   0.         341.94076136]\n",
      " [  0.         534.3422263  234.20697574]\n",
      " [  0.           0.           1.        ]]\n",
      "[[-3.00225860e-01  1.48224136e-01  1.49033658e-03  6.62245606e-05\n",
      "  -2.78325469e-02]]\n",
      "[[534.75798783   0.         341.4801265 ]\n",
      " [  0.         534.96955545 233.64983894]\n",
      " [  0.           0.           1.        ]]\n",
      "[[-2.96548154e-01  1.13868006e-01  1.44476302e-03  2.94839956e-04\n",
      "   4.73668193e-02]]\n",
      "[[534.07088364   0.         341.53407554]\n",
      " [  0.         534.11914595 232.94565259]\n",
      " [  0.           0.           1.        ]]\n",
      "[[-2.92971637e-01  1.07706962e-01  1.31038376e-03 -3.11018780e-05\n",
      "   4.34798110e-02]]\n"
     ]
    }
   ],
   "source": [
    "# https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html\n",
    "\n",
    "import glob\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6 * 7, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0: 7, 0: 6].T.reshape(-1, 2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = []  # 3d point in real world space\n",
    "imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "images = glob.glob('data/images/*.jpg')\n",
    "print(images)\n",
    "\n",
    "for image in images:\n",
    "    img = cv2.imread(image)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7, 6), None)\n",
    "\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        img = cv2.drawChessboardCorners(img, (7, 6), corners2, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "        print(mtx)\n",
    "        print(dist)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "detector1 = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref3DModel():\n",
    "    modelPoints = [[0.0,0.0,0.0],\n",
    "                   [0.0,-330.0,-65.0],\n",
    "                   [-255.0,170.0,-135.0],\n",
    "                   [225.0,170.0,-135.0],\n",
    "                   [-150.0,-150.0,-125.0],\n",
    "                   [150.0,-150.0,-125.0]]\n",
    "    return np.array(modelPoints,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref2DImagePoints(shape):\n",
    "    imagePoints = [[shape.part(30).x,shape.part(30).y],\n",
    "                   [shape.part(8).x,shape.part(8).y],\n",
    "                   [shape.part(36).x,shape.part(36).y],\n",
    "                   [shape.part(45).x,shape.part(45).y],\n",
    "                   [shape.part(48).x,shape.part(48).y],\n",
    "                   [shape.part(54).x,shape.part(54).y]]\n",
    "    return np.array(imagePoints,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def CameraMatrix(fl,center):\n",
    "#     cameraMatrix = [[fl,1,center[0]],\n",
    "#                     [0,fl,centre[1]],\n",
    "#                     [0,0,1]]\n",
    "#     return np.array(cameraMatrix,dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPolyline(img,shapes,start,end,isClosed=False):\n",
    "    points = []\n",
    "    for i in range(start,end+1):\n",
    "        point = [shapes.part(i).x,shapes.part(i).y]\n",
    "        points.append(point)\n",
    "    points = np.array(points,dtype=np.float32)\n",
    "    cv2.polylines(img,np.int32([points]),isClosed,(255,80,0),thickness=1,lineType=cv2.LINE_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img,shapes):\n",
    "    drawPolyline(img, shapes, 0, 16)\n",
    "    drawPolyline(img, shapes, 17, 21)\n",
    "    drawPolyline(img, shapes, 22, 26)\n",
    "    drawPolyline(img, shapes, 27, 30)\n",
    "    drawPolyline(img, shapes, 30, 35, True)\n",
    "    drawPolyline(img, shapes, 36, 41, True)\n",
    "    drawPolyline(img, shapes, 42, 47, True)\n",
    "    drawPolyline(img, shapes, 48, 59, True)\n",
    "    drawPolyline(img, shapes, 60, 67, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EYE_AR_THRESH = 0.3\n",
    "EYE_AR_CONSEC_FRAMES = 30\n",
    "YAWN_THRESH = 20\n",
    "alarm_status = False\n",
    "alarm_status2 = False\n",
    "saying = False\n",
    "COUNTER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alarm(m):\n",
    "    while alarm_status:\n",
    "        print(\"Call\")\n",
    "        myText = m\n",
    "        language = 'en'\n",
    "        output = gTTS(text=myText,lang=language,slow=False)\n",
    "        output.save(\"output.mp3\")\n",
    "        playsound(\"output.mp3\")\n",
    "    \n",
    "    if alarm_status2:\n",
    "        print(\"Call\")\n",
    "        saying = True\n",
    "        myText = m\n",
    "        language = 'en'\n",
    "        output = gTTS(text=myText,lang=language,slow=False)\n",
    "        output.save(\"output.mp3\")\n",
    "        playsound(\"output.mp3\")\n",
    "        saying = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    A = np.linalg.norm(eye[1]-eye[5])\n",
    "    B = np.linalg.norm(eye[2]-eye[4])\n",
    "    C = np.linalg.norm(eye[0]-eye[3])\n",
    "    \n",
    "    ear = (A+B)/(2.0*C)\n",
    "    \n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_ear(shape):\n",
    "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "    \n",
    "    leftEye = shape[lStart:lEnd]\n",
    "    rightEye = shape[rStart:rEnd]\n",
    "    \n",
    "    leftEAR = eye_aspect_ratio(leftEye)\n",
    "    rightEAR = eye_aspect_ratio(rightEye)\n",
    "    \n",
    "    ear = (leftEAR+rightEAR)/2.0\n",
    "    return (ear,leftEye,rightEye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lip_distance(shape):\n",
    "    top_lip = shape[50:53]\n",
    "    top_lip = np.concatenate((top_lip, shape[61:64]))\n",
    "    \n",
    "    low_lip = shape[56:59]\n",
    "    low_lip = np.concatenate((low_lip, shape[65:68]))\n",
    "    \n",
    "    top_mean = np.mean(top_lip,axis=0)\n",
    "    low_mean = np.mean(low_lip,axis=0)\n",
    "    \n",
    "    distance = abs(top_mean[1]-low_mean[1])\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open output.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close output.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: output.mp3\n",
      "Exception in thread Thread-6 (alarm):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\.conda\\envs\\aireadiness\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\ASUS\\.conda\\envs\\aireadiness\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_17108\\2527827591.py\", line 8, in alarm\n",
      "  File \"C:\\Users\\ASUS\\.conda\\envs\\aireadiness\\lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"C:\\Users\\ASUS\\.conda\\envs\\aireadiness\\lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open output.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    GAZE = \"Face Not Found\"\n",
    "    ret,img = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector1.detectMultiScale(gray, scaleFactor=1.1,minNeighbors=5, minSize=(30, 30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    #for rect in rects:\n",
    "    for (x, y, w, h) in rects:\n",
    "        rect = dlib.rectangle(int(x), int(y), int(x + w),int(y + h))\n",
    "        \n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        eye = final_ear(shape)\n",
    "        ear = eye[0]\n",
    "        leftEye = eye [1]\n",
    "        rightEye = eye[2]\n",
    "        \n",
    "#         leftEyeHull = cv2.convexHull(leftEye)\n",
    "#         rightEyeHull = cv2.convexHull(rightEye)\n",
    "#         cv2.drawContours(img, [leftEyeHull], -1, (0, 0, 255), 1)\n",
    "#         cv2.drawContours(, [rightEyeHull], -1, (0, 0, 255), 1)\n",
    "\n",
    "        if ear < EYE_AR_THRESH:\n",
    "            COUNTER += 1\n",
    "\n",
    "            if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                if alarm_status == False:\n",
    "                    alarm_status = True\n",
    "                    t = Thread(target=alarm, args=('wake up sid',))\n",
    "                    t.deamon = True\n",
    "                    t.start()\n",
    "\n",
    "                cv2.putText(img, \"Not attenion ALERT!\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        else:\n",
    "            COUNTER = 0\n",
    "            alarm_status = False\n",
    "     \n",
    "    faces = detector(cv2.cvtColor(img,cv2.COLOR_BGR2RGB),0)\n",
    "    face3Dmodel = ref3DModel()\n",
    "    \n",
    "    for face in faces:\n",
    "        shape = predictor(cv2.cvtColor(img,cv2.COLOR_BGR2RGB),face)\n",
    "        \n",
    "        draw(img,shape)\n",
    "        \n",
    "        shape1 = face_utils.shape_to_np(shape)\n",
    "\n",
    "        distance = lip_distance(shape1)\n",
    "\n",
    "        refImgPts = ref2DImagePoints(shape)\n",
    "        \n",
    "        height,width,channels = img.shape\n",
    "#         focalLength = args.focal * width\n",
    "#         cameraMatrix = cameraMatrix(focalLength,(height/2,width/2))\n",
    "        \n",
    "        mdists = np.zeros((4,1),dtype=np.float64)\n",
    "        \n",
    "        success,rotationVector,translationVector = cv2.solvePnP(face3Dmodel,refImgPts,mtx,mdists)\n",
    "        \n",
    "        noseEndPoints3D = np.array([[0,0,1000.0]],dtype=np.float64)\n",
    "        noseEndPoint2D,jacobian = cv2.projectPoints(noseEndPoints3D, rotationVector, translationVector, mtx, mdists)\n",
    "        \n",
    "        rmat, jac = cv2.Rodrigues(rotationVector)\n",
    "        angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "        \n",
    "        if angles[1] < -15:\n",
    "            GAZE = \"Looking: Left, Probably unattentive\"\n",
    "        elif angles[1] > 15:\n",
    "            GAZE = \"Looking: Right, Probably unattentive\"\n",
    "        else:\n",
    "            GAZE = \"Forward, OK\"\n",
    "            \n",
    "#         if ear < EYE_AR_THRESH:\n",
    "#             COUNTER += 1\n",
    "\n",
    "#             if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "#                 if alarm_status == False:\n",
    "#                     alarm_status = True\n",
    "#                     t = Thread(target=alarm, args=('wake up sir',))\n",
    "#                     t.deamon = True\n",
    "#                     t.start()\n",
    "\n",
    "#                 cv2.putText(img, \"DROWSINESS ALERT!\", (10, 30),\n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "#         else:\n",
    "#             COUNTER = 0\n",
    "#             alarm_status = False\n",
    "\n",
    "        if (distance > YAWN_THRESH):\n",
    "                cv2.putText(img, \"Yawn Alert, Probably unattentive\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        else:\n",
    "            alarm_status2 = False\n",
    "\n",
    "            \n",
    "    cv2.putText(img,GAZE,(20,20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,80),2)\n",
    "    cv2.imshow(\"Head Pose\",img)\n",
    "    \n",
    "    key = cv2.waitKey(10) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
